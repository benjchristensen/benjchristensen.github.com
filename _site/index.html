<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Ben Christensen &middot; 
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class=" layout-reverse">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
          Ben Christensen
      </h1>
      <p class="lead">Software Engineer at Netflix, previously Apple</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/toc/">Posts</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="http://twitter.com/benjchristensen">Twitter</a>
      <a class="sidebar-nav-item" href="http://github.com/benjchristensen">Github</a>
      <a class="sidebar-nav-item" href="http://github.com/ReactiveX/RxJava">&bull; RxJava</a>
      <a class="sidebar-nav-item" href="http://github.com/Netflix/Hystrix">&bull; Hystrix</a>
      <a class="sidebar-nav-item" href="http://linkedin.com/in/benjchristensen">LinkedIn</a>
    </nav>


    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/architecture/code/infrastructure/performance/production/production%20problems/resilience%20engineering/tools/2013/06/10/application-resilience-in-a-service-oriented-architecture-using-hystrix/">
        Application Resilience in a Service-Oriented Architecture using Hystrix
      </a>
    </h1>

    <span class="post-date">10 Jun 2013</span>

    <p>Originally written for <a href="http://programming.oreilly.com/2013/06/application-resilience-in-a-service-oriented-architecture.html">programming.oreilly.com</a>:</p>

<p>Web-scale applications such as Netflix serve millions of customers using thousands of servers across multiple data centers. Unmitigated system failures impact user experience, product image, company brand and potentially even revenue. Service-oriented architectures such as these are too complex to completely understand or control and must be treated accordingly. The relationships between nodes are constantly changing as actors within the system independently evolve. Failure in the form of errors and latency will emerge from these relationships and resilient systems can easily &quot;drift&quot; into states of vulnerability. Infrastructure alone cannot be relied upon to achieve resilience. Application instances, as components of a complex system, must isolate failure and constantly audit for change.</p>

<p>At Netflix, we have spent a lot of time and energy engineering resilience into our systems. Among the tools we have built is <a href="https://github.com/Netflix/Hystrix/wiki">Hystrix</a> which specifically focuses on failure isolation and graceful degradation. It evolved from a series of production incidents involving saturated connection and/or thread pools, cascading failures, and misconfigurations of pools, queues, timeouts and other such &quot;minor mistakes&quot; which led to major user impact.</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/06/blocked-requests-640.png" alt=""></p>

<p>This open source library follows these principles in protecting our systems when novel failures inevitably occur:</p>

<ul>
<li><p>Isolate client network interaction using the bulkhead and circuit breaker patterns.</p></li>
<li><p>Fallback and degrade gracefully when possible.</p></li>
<li><p>Fail fast when fallbacks aren&#39;t available and rapidly recover.</p></li>
<li><p>Monitor, alert and push configuration changes with low latency (seconds).</p></li>
</ul>

<p>Restricting concurrent access to a given backend service has proven to be an effective form of <a href="http://www.infoq.com/interviews/Building-Resilient-Systems-Michael-Nygard">bulkheading</a> as it limits the resource utilization to a concurrent request limit smaller than the total resources available in an application instance. We do this using two techniques, <a href="https://github.com/Netflix/Hystrix/wiki/How-it-Works#wiki-Isolation">thread pools and semaphores</a>. Both provide the essential quality of restricting concurrent access while threads provide the added benefit of timeouts so the caller can &quot;walk away&quot; if the underlying work is latent.</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/06/failing-dependency-640.png" alt=""></p>

<p>Isolating functionality rather than the transport layer is valuable as it not only extends the bulkhead beyond network failures and latency, but also those caused by client code. Examples include request validation logic, conditional routing to different or multiple backends, request serialization, response deserialization, response validation, and decoration. Network responses can be latent, corrupted or incompatibly changed at any time which in turn can result in unexpected failures in this application logic.</p>

<p>Mixed environments will also have several types of clients for the many different types of backends. Each has different configurations and most clients don&#39;t expose themselves easily for auditing or modification in a production environment. Unfortunately it is also generally true that default configurations are not optimal and despite best efforts these leak into a system (particularly via transitive dependencies) and it only takes one misconfigured client to expose a vulnerability that results in a system outage.</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/06/failing-dependency-box-640.png" alt=""></p>

<p>Bulkheading around all of this - transport layer, network clients and client code - permits reliable protection against changing behavior, misconfigurations, transitive dependencies performing unexpected network activity, response handling failures and overall latency regardless of where it comes from.</p>

<p>Applying bulkheads at the functional level also enables addition of business logic for <a href="https://github.com/Netflix/Hystrix/wiki/How-To-Use#wiki-Fallback">fallback</a> behavior to allow graceful degradation when failure occurs. Failure may come via network or client code exceptions, timeouts, short-circuiting, or concurrent request throttling.  All of them, however, can now be <a href="https://github.com/Netflix/Hystrix/wiki/How-it-Works#wiki-Flow">handled</a> with the same &quot;failure handler&quot; to provide fallback responses. Some functionality may not be able to gracefully degrade so will &quot;fail fast&quot; and shed load until recovery, but many others can return stale data, use secondary systems, use defaults or other such <a href="https://github.com/Netflix/Hystrix/wiki/How-To-Use#wiki-Common-Patterns">patterns</a>.</p>

<p><a href="https://github.com/Netflix/Hystrix/wiki/Operations">Operations and insight</a> into what is going on is equally important to the actual isolation techniques. The key aspects of this are low latency metrics, low latency configuration changes and common insight into all service relationships regardless of how the network transport is being implemented.</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/06/dashboard-annoted-circuit-640.png" alt=""></p>

<p>A low-latency (~1 second) <a href="https://github.com/Netflix/Turbine">metrics stream</a> is exposed to aggregate metrics from all application instances in a cluster. We use this stream for alerting and <a href="https://github.com/Netflix/Hystrix/wiki/Dashboard">dashboards</a> (as shown in a video clip below and the annotated image above) to provide visualizations of traffic, performance and health of all bulkheads on a system. Near real-time metrics have improved mean-time-to-detection (MTTD) and mean-time-to-recovery (MTTR) and increased operational effectiveness when doing deployments or dealing with production incidents. Configuration changes visually roll across a cluster of servers in seconds and the impact is seen immediately.</p>

<p>[youtube http://www.youtube.com/watch?v=zWM7oAbVL4g&amp;w=640&amp;h=360]</p>

<p>Auditing production is essential to maintaining a resilient system. <a href="http://techblog.netflix.com/2011/07/netflix-simian-army.html">Latency Monkey</a> is used in production to inject latency into the system relationships of the service-oriented architecture. Latency can be far more damaging to a distributed system and is more difficult to address than &quot;fast fail&quot; of machines or code. While running latency simulations Hystrix real-time monitoring allows us to rapidly see the impact, determine if we are safe or need to end the test. Most times these simulations &quot;light up&quot; a Hystrix bulkhead on our dashboards to show they are doing their job to isolate the latency but sometimes we reveal a regression and quickly discover it, end the test and pursue a resolution which is validated in the next test run.</p>

<p>Another form of auditing being applied is tracking all network traffic leaving the JVM and finding those not isolated behind a bulkhead. We use this like a &quot;<a href="https://github.com/Netflix/Hystrix/tree/master/hystrix-contrib/hystrix-network-auditor-agent">canary in a coalmine</a>&quot; that permanently runs and takes a small percentage of production traffic to find network traffic that springs up without isolation. This can occur in the initial canary deployment with new code, or it may occur when unexpected code paths are enabled via transitive dependencies when AB tests are turned on or production configuration is changed and pushed out to a fleet of existing servers.</p>

<p>Graceful degradation is not purely a server-side consideration and our device and UI teams play an equally important role in making the user experience robust and capable of degrading gracefully. For example, the server can use bulkheading to isolate failure and choose to &quot;fail silently&quot; on a portion of a request considered optional but UIs must behave correctly or we may cause the client to fail as it tries to render data not present in a response. Fault injection via Hystrix <a href="http://netflix.github.io/Hystrix/javadoc/com/netflix/hystrix/strategy/executionhook/HystrixCommandExecutionHook.html">execution hooks</a> enables device teams to target specific UIs, devices and accounts to test failure, latency and fallback scenarios and determine whether the client code responds as it should. </p>

<p>Engineering resilience into an application is critical to achieving fault and latency tolerance. Operational considerations and support by client applications are equally important. These principles can be applied in many different ways and approaches will differ by language, technology stack and personal preference but hopefully our experiences, and perhaps even our <a href="http://netflix.github.io">open source software</a>, can inspire improved resilience in your systems.</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/06/hystrix-logo-tagline-640.png" alt=""></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/architecture/code/resilience%20engineering/tools/2013/05/24/hystrix-in-may-2013-thoughtworks-tech-radar/">
        Hystrix in May 2013 ThoughtWorks Tech Radar
      </a>
    </h1>

    <span class="post-date">24 May 2013</span>

    <p><a href="https://github.com/Netflix/Hystrix">Hystrix</a> was listed in the <a href="http://thoughtworks.fileburst.com/assets/technology-radar-may-2013.pdf">May 2013 Tech Radar</a> by ThoughtWorks as &quot;Assess&quot; under the Tools section.</p>

<blockquote>Managing dependencies in distributed systems can become 
complicated, and is a problem more people are facing with the 
move to finer-grained micro services. Hystrix is a library for 
the JVM from Netflix that implements patterns for dealing with 
downstream failure, offers real-time monitoring of connections, 
and caching and batching mechanisms to make inter-service 
dependencies more efficient.</blockquote>

<p><img src="http://benjchristensen.files.wordpress.com/2013/01/hystrix-logo-tagline-github-link-640.png?width=640&amp;height=181" alt=""></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/architecture/code/infrastructure/performance/production/resilience%20engineering/2013/05/01/functional-reactive-programming-in-the-netflix-api-qcon-london-2013/">
        Functional Reactive Programming in the Netflix API - QCon London 2013
      </a>
    </h1>

    <span class="post-date">01 May 2013</span>

    <p>I had the opportunity to speak at QCon London 2013 and present <a href="http://qconlondon.com/london-2013/speaker/Ben+Christensen">Functional Reactive Programming in the Netflix API</a>:</p>

<ul>
<li><p><a href="https://speakerdeck.com/benjchristensen/functional-reactive-programming-in-the-netflix-api-qcon-london-2013">Slides on Speakerdeck</a></p></li>
<li><p><a href="http://www.infoq.com/presentations/netflix-functional-rx">Video on InfoQ</a></p></li>
<li><p><a href="http://www.infoq.com/interviews/christensen-hystrix-rxjava">Interview on InfoQ on Resilience at Netflix with Hystrix, Reactive Programming for the JVM with RxJava</a></p></li>
</ul>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/architecture/code/performance/production/2013/05/01/functional-reactive-in-the-netflix-api-with-rxjava/">
        Functional Reactive in the Netflix API with RxJava
      </a>
    </h1>

    <span class="post-date">01 May 2013</span>

    <p>Originally written for and posted on the <a href="http://techblog.netflix.com/2013/02/rxjava-netflix-api.html">Netflix Tech Blog</a>.</p>

<p>by <a href="https://twitter.com/benjchristensen/">Ben Christensen</a> and <a href="https://twitter.com/jhusain">Jafar Husain</a></p>

<p>Our recent post on <a href="http://techblog.netflix.com/2013/01/optimizing-netflix-api.html">optimizing the Netflix API</a>  introduced how our web service endpoints are implemented using a &quot;functional reactive programming&quot; (FRP) model for composition of asynchronous callbacks from our service layer. </p>

<p>This post takes a closer look at how and why we use the FRP model and introduces our open source project RxJava – a Java implementation of <a href="https://rx.codeplex.com">Rx (Reactive Extensions)</a>.</p>

<h2>Embrace Concurrency</h2>

<p>Server-side concurrency is needed to effectively reduce network chattiness. Without concurrent execution on the server, a single &quot;heavy&quot; client request might not be much better than many &quot;light&quot; requests because each network request from a device naturally executes in parallel with other network requests.  If the server-side execution of a collapsed &quot;heavy&quot; request does not achieve a similar level of parallel execution it may be slower than the multiple &quot;light&quot; requests even accounting for saved network latency.</p>

<h2>Futures are Expensive to Compose</h2>

<p><a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Future.html">Futures</a> are straight-forward to use for a <a href="https://gist.github.com/4670979">single level</a> of asynchronous execution but they start to add non-trivial complexity when they&#39;re <a href="https://gist.github.com/4671081">nested</a>.</p>

<p>Conditional asynchronous execution flows become <a href="https://gist.github.com/4671081#file-futuresb-java-L163">difficult</a> to optimally compose (particularly as latencies of each request vary at runtime) using Futures. It <a href="http://www.amazon.com/gp/product/0321349601?ie=UTF8&amp;tag=none0b69&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321349601">can be done</a> of course, but it quickly becomes complicated (and thus error prone) or prematurely blocks on &#39;Future.get()&#39;, eliminating the benefit of asynchronous execution.</p>

<h2>Callbacks Have Their Own Problems</h2>

<p>Callbacks offer a solution to the tendency to block on Future.get() by not allowing anything to block. They are naturally efficient because they execute when the response is ready.</p>

<p>Similar to Futures though, they are easy to use with a single level of asynchronous execution but become <a href="https://gist.github.com/4677544">unwieldy</a> with nested composition.</p>

<h2>Reactive</h2>

<p>Functional reactive offers efficient execution and composition by providing a collection of operators capable of filtering, selecting, transforming, combining and composing Observable&#39;s.</p>

<p>The Observable data type can be thought of as a &quot;push&quot; equivalent to <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Iterable.html">Iterable</a> which is &quot;pull&quot;. With an Iterable, the consumer pulls values from the producer and the thread blocks until those values arrive. By contrast with the Observable type, the producer pushes values to the consumer whenever values are available.  This approach is more flexible, because values can arrive synchronously or asynchronously.</p>

<p>The Observable type adds two missing semantics to the Gang of Four&#39;s <a href="http://en.wikipedia.org/wiki/Observer_pattern">Observer</a> pattern, which are available in the Iterable type:  </p>

<ol>
<li><p>The ability for the producer to signal to the consumer that there is no more data available.</p></li>
<li><p>The ability for the producer to signal to the consumer that an error has occurred.</p></li>
</ol>

<p>With these two simple additions, we have unified the Iterable and Observable types. The only difference between them is the direction in which the data flows. This is very important because now any operation we perform on an Iterable, can also be performed on an Observable. Let&#39;s take a look at an example ...</p>

<p>[gist https://gist.github.com/4676544 /]</p>

<h2>Observable Service Layer</h2>

<p>The Netflix API takes advantage of Rx by making the entire service layer asynchronous (or at least appear so) - all &quot;service&quot; methods return an Observable<T>.</p>

<p>Making all return types Observable combined with a functional programming model frees up the service layer implementation to safely use concurrency. It also enables the service layer implementation to:</p>

<ul>
<li><p>conditionally return immediately from a cache</p></li>
<li><p>block instead of using threads if resources are constrained</p></li>
<li><p>use multiple threads</p></li>
<li><p>use non-blocking IO</p></li>
<li><p>migrate an underlying implementation from network based to in-memory cache</p></li>
</ul>

<p>This can all happen without ever changing how client code interacts with or composes responses.</p>

<p>In short, client code treats all interactions with the API as asynchronous but the implementation chooses if something is blocking or non-blocking.</p>

<p>This next example code demonstrates how a service layer method can choose whether to synchronously return data from an in-memory cache or asynchronously retrieve data from a remote service and callback with the data once retrieved. In both cases the client code consumes it the same way.</p>

<p>[gist https://gist.github.com/4675568 /]</p>

<p>Retaining this level of control in the service layer is a major architectural advantage particularly for maintaining and optimizing functionality over time. Many different endpoint implementations can be coded against an Observable API and they work efficiently and correctly with the current thread or one or more worker threads backing their execution.</p>

<p>The following code demonstrates the consumption of an Observable API with a common Netflix use case – a grid of movies:</p>

<p>[gist https://gist.github.com/4679253 /]</p>

<p>That code is declarative and <a href="http://en.wikipedia.org/wiki/Lazy_evaluation">lazy</a> as well as functionally &quot;pure&quot; in that no mutation of state is occurring that would cause thread-safety issues.</p>

<p>The API Service Layer is now free to change the behavior of the methods &#39;getListOfLists&#39;, &#39;getVideos&#39;, &#39;getMetadata&#39;, &#39;getBookmark&#39; and &#39;getRating&#39; – some blocking others non-blocking but all consumed the same way.</p>

<p>In the example, &#39;getListOfLists&#39; pushes each &#39;VideoList&#39; object via &#39;onNext()&#39; and then &#39;getVideos()&#39; operates on that same parent thread. The implementation of that method could however change from blocking to non-blocking and the code would not need to change.</p>

<h2>RxJava</h2>

<p>RxJava is our implementation of Rx for the JVM and is available in the <a href="https://github.com/Netflix/RxJava">Netflix repository in Github</a>.</p>

<p>It is not yet feature complete with the .Net version of Rx, but what is implemented has been in use for the past year in production within the Netflix API. </p>

<p>We are open sourcing the code as version 0.5 as a way to acknowledgement that it&#39;s not yet feature complete. The outstanding work is logged in the <a href="https://github.com/Netflix/RxJava/issues?milestone=1&amp;state=open">RxJava Issues</a>.</p>

<p>Documentation is available on the <a href="https://github.com/Netflix/RxJava/wiki">RxJava Wiki</a> including links to material available on the internet.</p>

<p>Some of the goals of RxJava are:</p>

<ul>
<li><p>Stay close to the original Rx.Net implementation while adjusting naming conventions and idioms to Java</p></li>
<li><p>All contracts of Rx should be the same</p></li>
<li><p>Target the JVM not a language. The first languages supported (beyond Java itself) are <a href="https://github.com/Netflix/RxJava/tree/master/language-adaptors/rxjava-groovy">Groovy</a>, <a href="https://github.com/Netflix/RxJava/tree/master/language-adaptors/rxjava-clojure">Clojure</a>, <a href="https://github.com/Netflix/RxJava/tree/master/language-adaptors/rxjava-scala">Scala</a> and <a href="https://github.com/Netflix/RxJava/tree/master/language-adaptors/rxjava-jruby">JRuby</a>. New language adapters can be <a href="https://github.com/Netflix/RxJava/wiki/How-to-Contribute">contributed</a>.</p></li>
<li><p>Support Java 5 (to include Android support) and higher with an eventual goal to target a build for Java 8 with its lambda support.</p></li>
</ul>

<p>Here is an implementation of one of the examples above but using Clojure instead of Groovy:</p>

<p>[gist https://gist.github.com/4676533 /]</p>

<h1>Summary</h1>

<p>Functional reactive programming with RxJava has enabled Netflix developers to leverage server-side conconcurrency without the typical thread-safety and synchronization concerns. The API service layer implementation has control over concurrency primitives, which enables us to pursue system performance improvements without fear of breaking client code.</p>

<p>RxJava is effective on the server for us and it spreads deeper into our code the more we use it.</p>

<p>We hope you find the RxJava project as useful as we have and look forward to your contributions.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/architecture/code/infrastructure/performance/production/resilience%20engineering/2013/04/30/optimizing-the-netflix-api/">
        Optimizing the Netflix API
      </a>
    </h1>

    <span class="post-date">30 Apr 2013</span>

    <p>Originally written for and posted on the <a href="http://techblog.netflix.com/2013/01/optimizing-netflix-api.html">Netflix Tech Blog</a>:</p>

<p>About a year ago the Netflix API team began redesigning the API to improve performance and enable UI engineering teams within Netflix to optimize client applications for specific devices.  Philosophies of the redesign were introduced in a previous post about <a href="http://techblog.netflix.com/2012/07/embracing-differences-inside-netflix.html">embracing the differences</a> between the different clients and devices.</p>

<p>This post is part one of a series on the architecture of our redesigned API.</p>

<h1>Goals</h1>

<p>We had multiple goals in creating this system, as follows:</p>

<p>Reduce Chattiness</p>

<p>One of the key drivers in pursuing the <a href="http://techblog.netflix.com/2011/02/redesigning-netflix-api.html">redesign</a> in the first place was to reduce the chatty nature of our client/server communication, which could be hindering the overall performance of our device implementations.</p>

<p>Due to the generic and granular nature of the original REST-based Netflix API, each call returns only a portion of functionality for a given user experience, requiring client applications to make multiple calls that need to be assembled in order to render a single user experience.  This interaction model is illustrated in the following diagram:</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/05/90083-request-multi_1252.png" alt=""></p>

<p>To reduce the chattiness inherent in the REST API, the discrete requests in the diagram above should be collapsed into a single request optimized for a given client.  The benefit is that the device then pays the price of WAN latency once and leverages the low latency and more powerful hardware server-side. As a side effect, this also eliminates redundancies that occur for every incoming request.</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/05/7d4c6-request-single_1252.png" alt=""></p>

<p>A single optimized request such as this must embrace server-side parallelism to at least the same level as previously achieved through multiple network requests from the client.  Because the server-side parallelized requests are running in the same network, each one should be more performant than if it was executed from the device.  This must be achieved without each engineer implementing an endpoint needing to become an expert in low-level threading, synchronization, thread-safety, concurrent data structures, non-blocking IO and other such concerns.</p>

<p>Distribute API Development</p>

<p>A single team should not become a bottleneck nor need to have expertise on every client application to create optimized endpoints.  Rapid innovation through fast, decoupled development cycles across a wide variety of device types and distributed ownership and expertise across teams should be enabled.  Each client application team should be capable of implementing and operating their own endpoints and the corresponding requests/responses.</p>

<p>Mitigate Deployment Risks</p>

<p>The Netflix API is a Java application running on hundreds of servers processing 2+ billion incoming requests a day for millions of customers around the world.  The system must mitigate risks inherent in enabling rapid and frequent deployment by multiple teams with minimal coordination.</p>

<p>Support Multiple Languages</p>

<p>Engineers implementing endpoints come from a wide variety of backgrounds with expertise including Javascript, Objective-C, Java, C, C#, Ruby, Python and others.  The system should be able to support multiple languages at the same time.</p>

<p>Distribute Operations</p>

<p>Each client team will now manage the deployment lifecycle of their own web service endpoints.  Operational tools for monitoring, debugging, testing, canarying and rolling out code must be exposed to a distributed set of teams so teams can operate independently.</p>

<h1>Architecture</h1>

<p>To achieve the goals above our architecture distilled into a few key points:</p>

<ul>
<li><p>dynamic polyglot runtime</p></li>
<li><p>fully asynchronous service layer</p></li>
<li><p>functional reactive programming model</p></li>
</ul>

<p>The following diagram and subsequent annotations explain the architecture:</p>

<p><img src="http://benjchristensen.files.wordpress.com/2013/05/72a7d-architecture-overview_1252.png" alt=""></p>

<p>[1] Dynamic Endpoints</p>

<p>All new web service endpoints are now dynamically defined at runtime. New endpoints can be developed, tested, canaried and deployed by each client team without coordination (unless they depend on new functionality from the underlying API Service Layer shown at item 5 in which case they would need to wait until after those changes are deployed before pushing their endpoint).</p>

<p>[2] Endpoint Code Repository and Management</p>

<p>Endpoint code is published to a Cassandra multi-region cluster (globally replicated) via a RESTful Endpoint Management API used by client teams to manage their endpoints.</p>

<p>[3] Dynamic Polyglot JVM Language Runtime</p>

<p>Any JVM language can be supported so each team can use the language best suited to them.</p>

<p>The Groovy JVM language was chosen as our first supported language. The existence of first-class functions (closures), list/dictionary syntax, performance and debuggability were all aspects of our decision.  Moreover, Groovy provides syntax comfortable to a wide range of developers, which helps to reduce the learning curve for the first language on the platform.</p>

<p>[4 &amp; 5] Asynchronous Java API + Functional Reactive Programming Model</p>

<p>Embracing concurrency was a key requirement to achieve performance gains but abstracting away thread-safety and parallel execution implementation details from the client developers was equally important in reducing complexity and speeding up their rate of innovation.  Making the Java API fully asynchronous was the first step as it allows the underlying method implementations to control whether something is executed concurrently or not without the client code changing.  We chose a functional reactive approach to handling composition and conditional flows of asynchronous callbacks. Our implementation is modeled after <a href="https://rx.codeplex.com/">Rx Observables</a>.</p>

<p>[6] Hystrix Fault Tolerance</p>

<p>As we have described in a <a href="http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html">previous post</a>, all service calls to backend systems are made via the Hystrix fault tolerance layer (which was <a href="http://techblog.netflix.com/2012/11/hystrix.html">recently open sourced</a>, along with its <a href="http://techblog.netflix.com/2012/12/hystrix-dashboard-and-turbine.html">dashboard</a>) that isolates the dynamic endpoints and the API Service Layer from the inevitable failures that occur while executing billions of network calls each day from the API to backend systems.</p>

<p>The Hystrix layer is inherently mutlti-threaded due to its use of threads for isolating dependencies and thus is leveraged for concurrent execution of blocking calls to backend systems. These asynchronous requests are then composed together via the functional reactive framework.</p>

<p>[7] Backend Services and Dependencies</p>

<p>The API Service Layer abstracts away all backend services and dependencies behind facades.  As a result, endpoint code accesses “functionality” rather than a “system”.  This allows us to change underlying implementations and architecture with no or limited impact on the code that depends on the API.  For example, if a backend system is split into 2 different services, or 3 are combined into one, or a remote network call is optimized into an in-memory cache, none of these changes should affect endpoint code and thus the API Service Layer ensures that object models and other such tight-couplings are abstracted and not allowed to “leak” into the endpoint code.</p>

<p>Summary</p>

<p>The new Netflix API architecture is a significant departure from our previous generic RESTful API. </p>

<p>Dynamic JVM languages combined with an asynchronous Java API and the functional reactive programming model have proven to be a powerful combination to enable safe and efficient development of highly concurrent code.</p>

<p>The end result is a fault-tolerant, performant platform that puts control in the hands of those who know their target applications the best.</p>

<p>Following posts will provide further implementation and operational details about this new architecture.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>
